require(LiblineaR) # another implementation for RLogReg
require(xgboost) # The implementation
require(randomForest) # nice RF implementation
require(doParallel) #ugly parallel in R but useful
cl <- makePSOCKcluster(2)
registerDoParallel(cl)
rm(list=ls())  # clean env.
t1 <- Sys.time()
data.raw <- read.csv(file='device_failure.csv') # few records kernels function works fine
print(sum(is.na(data.raw))) # NOT NULLS! THANKS A LOT :D
data.raw %>% arrange(device, date) %>% mutate(date = ymd(date) ) -> data.raw
data.raw %>% group_by(device) %>% arrange(device, date) %>%
mutate( l.attribute1 = lag(attribute1),
l.attribute2 = lag(attribute2),
l.attribute3 = lag(attribute3),
l.attribute4 = lag(attribute4),
l.attribute5 = lag(attribute5),
l.attribute6 = lag(attribute6),
l.attribute7 = lag(attribute7),
l.attribute8 = lag(attribute8),
l.attribute9 = lag(attribute9)) -> data.raw
data.raw <- na.omit(data.raw)
n.fails.index <- which(data.raw$failure==1) #only 106 failures
nn.fails <- data.raw[ rep(n.fails.index, each=9) + -4:4, ]
head(nn.fails, 50 )
data.raw %>% filter(failure==1) %>% group_by(device) %>% summarise(n=n()) -> t
summary(t$n)
table(data.raw$failure) / dim(data.raw)[1]
summary(data.raw)
device.with.failures <- unique(data.raw$device[n.fails.index] )
data.sample <- data.raw[ data.raw$device %in% device.with.failures, ]
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
index.columns <- c(2, 3, 4, 7, 8, 9:18) + 3
# log features selected
data.sample[, names(data.sample)[index.columns]] <-
log(data.sample[, names(data.sample)[index.columns]] + 1 )
# standar features
index.columns <- grep('attr', names(data.sample))
summary(data.sample)
for ( i in index.columns ){
temp <- data.sample[, names(data.sample)[i]]
data.sample[, names(data.sample)[i]] <- scale(temp)
}
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
createPartition <- function(data_, p=0.7){
# Inputs: data_ (data.frame) to split
#         p (numeric): dataframe's proportion for train sample
t <- unique(data_$device)
n <- length(t)
n.p <- round(n*p, 0)
t.sample <- sample(t, n.p)
train.index <- which( data_$device %in% t.sample)
return(train.index)
}
f1 <- function (data, lev = NULL, model = NULL) {
# Function requiere to calculate F1 score within caret::train , see doc.
precision <- posPredValue(data$pred, data$obs, positive = "Failure")
recall  <- sensitivity(data$pred, data$obs, positive = "Failure")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
return(f1_val)
}
set.seed(0)
data.sample$failure <- factor(data.sample$failure)
levels(data.sample$failure) <- c('NoFailure', 'Failure')
train.index <- createPartition(data.sample)
data.sample$date <- data.sample$device <- NULL
train <- data.sample[train.index, ]
test <- data.sample[-train.index, ]
fit.control <- trainControl(  method = 'repeatedcv', number = 10, repeats = 3,
allowParallel = TRUE, classProbs = TRUE,
summaryFunction = f1,  sampling =  "up")
set.seed(0)
gbmFit1 <- train(failure ~ ., data = train, method = "gbm", trControl = fit.control,
verbose = FALSE)
xgb.Fit1 <- train(failure ~ ., data = train, method = "xgbTree", #tuneLength = 5, search= 'random',
trControl = fit.control,
verbose = FALSE)
rf.Fit1 <- train(failure ~ ., data = train, method = "rf", trControl = fit.control,
verbose = FALSE)
rlg.Fit1 <- train(failure ~ ., data = train, method = "regLogistic",
trControl = fit.control, verbose = FALSE)
resamps <- resamples(list(GBM = gbmFit1, XGB = xgb.Fit1,
RF = rf.Fit1, RLG=rlg.Fit1  ))
summary(resamps)
#summary(diff(resamps))
t2 <- Sys.time()
t2 - t1
confusionMatrix(predict(rf.Fit1$finalModel,test), test$failure)
confusionMatrix(predict(xgb.Fit1,test), test$failure)
device.with.failures <- unique(data.raw$device[n.fails.index] )
data.sample <- data.raw[ data.raw$device %in% device.with.failures, ]
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
t3 <- Sys.time()
set.seed(0)
tune_grid <- expand.grid(nrounds=c(100,300), max_depth = c(4:7), eta = c(0.05, 1),   gamma = c(0.01),
colsample_bytree = c(0.75), subsample = c(0.50),  min_child_weight = c(0))
xgb_fit <- train(failure ~., data = train, method = "xgbTree",
trControl= fit.control,
tuneGrid = tune_grid,
tuneLength = 10)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, error = FALSE, message = FALSE, fig.height = 3, fig.width = 5)
# html_notebook
packs <- c('lubridate', 'dplyr', 'ggplot2', 'caret', 'MLmetrics', 'gbm',
'e1071', 'LiblineaR',
'xgboost', 'randomForest', 'doParallel')
index <- packs %in% row.names(installed.packages())
if (any(!index)){
sapply(packs[!index], FUN=install.packages )
}
require(lubridate) # easy handle datetimes
require(dplyr) # like SQL in R, and also load pipe operator
require(ggplot2) # easy, fast  and nice plots
require(caret) # a toolbox
require(MLmetrics) # metric in one line
require(gbm) # boosting alg.
require(e1071) # numerical rutines for svm implementation
require(LiblineaR) # another implementation for RLogReg
require(xgboost) # The implementation
require(randomForest) # nice RF implementation
require(doParallel) #ugly parallel in R but useful
cl <- makePSOCKcluster(2)
registerDoParallel(cl)
rm(list=ls())  # clean env.
t1 <- Sys.time()
data.raw <- read.csv(file='device_failure.csv') # few records kernels function works fine
print(sum(is.na(data.raw))) # NOT NULLS! THANKS A LOT :D
data.raw %>% arrange(device, date) %>% mutate(date = ymd(date) ) -> data.raw
data.raw %>% group_by(device) %>% arrange(device, date) %>%
mutate( l.attribute1 = lag(attribute1),
l.attribute2 = lag(attribute2),
l.attribute3 = lag(attribute3),
l.attribute4 = lag(attribute4),
l.attribute5 = lag(attribute5),
l.attribute6 = lag(attribute6),
l.attribute7 = lag(attribute7),
l.attribute8 = lag(attribute8),
l.attribute9 = lag(attribute9)) -> data.raw
data.raw <- na.omit(data.raw)
n.fails.index <- which(data.raw$failure==1) #only 106 failures
nn.fails <- data.raw[ rep(n.fails.index, each=9) + -4:4, ]
head(nn.fails, 50 )
data.raw %>% filter(failure==1) %>% group_by(device) %>% summarise(n=n()) -> t
summary(t$n)
table(data.raw$failure) / dim(data.raw)[1]
summary(data.raw)
device.with.failures <- unique(data.raw$device[n.fails.index] )
data.sample <- data.raw[ data.raw$device %in% device.with.failures, ]
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
index.columns <- c(2, 3, 4, 7, 8, 9:18) + 3
# log features selected
data.sample[, names(data.sample)[index.columns]] <-
log(data.sample[, names(data.sample)[index.columns]] + 1 )
# standar features
index.columns <- grep('attr', names(data.sample))
summary(data.sample)
for ( i in index.columns ){
temp <- data.sample[, names(data.sample)[i]]
data.sample[, names(data.sample)[i]] <- scale(temp)
}
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
createPartition <- function(data_, p=0.7){
# Inputs: data_ (data.frame) to split
#         p (numeric): dataframe's proportion for train sample
t <- unique(data_$device)
n <- length(t)
n.p <- round(n*p, 0)
t.sample <- sample(t, n.p)
train.index <- which( data_$device %in% t.sample)
return(train.index)
}
f1 <- function (data, lev = NULL, model = NULL) {
# Function requiere to calculate F1 score within caret::train , see doc.
precision <- posPredValue(data$pred, data$obs, positive = "Failure")
recall  <- sensitivity(data$pred, data$obs, positive = "Failure")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
return(f1_val)
}
set.seed(0)
data.sample$failure <- factor(data.sample$failure)
levels(data.sample$failure) <- c('NoFailure', 'Failure')
train.index <- createPartition(data.sample)
data.sample$date <- data.sample$device <- NULL
train <- data.sample[train.index, ]
test <- data.sample[-train.index, ]
fit.control <- trainControl(  method = 'repeatedcv', number = 10, repeats = 3,
allowParallel = TRUE, classProbs = TRUE,
summaryFunction = f1,  sampling =  "up")
set.seed(0)
gbmFit1 <- train(failure ~ ., data = train, method = "gbm", trControl = fit.control,
verbose = FALSE)
xgb.Fit1 <- train(failure ~ ., data = train, method = "xgbTree", #tuneLength = 5, search= 'random',
trControl = fit.control,
verbose = FALSE)
rf.Fit1 <- train(failure ~ ., data = train, method = "rf", trControl = fit.control,
verbose = FALSE)
rlg.Fit1 <- train(failure ~ ., data = train, method = "regLogistic",
trControl = fit.control, verbose = FALSE)
resamps <- resamples(list(GBM = gbmFit1, XGB = xgb.Fit1,
RF = rf.Fit1, RLG=rlg.Fit1  ))
summary(resamps)
#summary(diff(resamps))
t2 <- Sys.time()
t2 - t1
confusionMatrix(predict(rf.Fit1$finalModel,test), test$failure)
confusionMatrix(predict(xgb.Fit1,test), test$failure)
t3 <- Sys.time()
set.seed(0)
tune_grid <- expand.grid(nrounds=c(100,300), max_depth = c(4:7), eta = c(0.05, 1),   gamma = c(0.01),
colsample_bytree = c(0.75), subsample = c(0.50),  min_child_weight = c(0))
xgb_fit <- train(failure ~., data = train, method = "xgbTree",
trControl= fit.control,
tuneGrid = tune_grid,
tuneLength = 10)
tune_grid <- expand.grid(.mtry = (1:16))
rf_fit <- train(failure ~., data = train, method = "rf",
trControl= fit.control,
tuneGrid = tune_grid,
tuneLength = 10)
t3 <- Sys.time()
set.seed(0)
tune_grid <- expand.grid(nrounds=c(100,300), max_depth = c(4:7), eta = c(0.05, 1),   gamma = c(0.01),
colsample_bytree = c(0.75), subsample = c(0.50),  min_child_weight = c(0))
xgb_fit <- train(failure ~., data = train, method = "xgbTree",
trControl= fit.control,
tuneGrid = tune_grid,
tuneLength = 10)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, error = FALSE, message = FALSE, fig.height = 3, fig.width = 5)
require(lubridate) # easy handle datetimes
require(dplyr) # like SQL in R, and also load pipe operator
require(ggplot2) # easy, fast  and nice plots
require(caret) # a toolbox
require(MLmetrics) # metric in one line
require(gbm) # boosting alg.
require(e1071) # numerical rutines for svm implementation
require(LiblineaR) # another implementation for RLogReg
require(xgboost) # The implementation
require(randomForest) # nice RF implementation
require(doParallel) #ugly parallel in R but useful
cl <- makePSOCKcluster(2)
registerDoParallel(cl)
rm(list=ls())  # clean env.
t1 <- Sys.time()
data.raw <- read.csv(file='device_failure.csv') # few records kernels function works fine
print(sum(is.na(data.raw))) # NOT NULLS! THANKS A LOT :D
data.raw %>% arrange(device, date) %>% mutate(date = ymd(date) ) -> data.raw
data.raw %>% group_by(device) %>% arrange(device, date) %>%
mutate( l.attribute1 = lag(attribute1),
l.attribute2 = lag(attribute2),
l.attribute3 = lag(attribute3),
l.attribute4 = lag(attribute4),
l.attribute5 = lag(attribute5),
l.attribute6 = lag(attribute6),
l.attribute7 = lag(attribute7),
l.attribute8 = lag(attribute8),
l.attribute9 = lag(attribute9)) -> data.raw
data.raw <- na.omit(data.raw)
n.fails.index <- which(data.raw$failure==1) #only 106 failures
nn.fails <- data.raw[ rep(n.fails.index, each=9) + -4:4, ]
head(nn.fails, 50 )
data.raw %>% filter(failure==1) %>% group_by(device) %>% summarise(n=n()) -> t
summary(t$n)
table(data.raw$failure) / dim(data.raw)[1]
summary(data.raw)
device.with.failures <- unique(data.raw$device[n.fails.index] )
data.sample <- data.raw[ data.raw$device %in% device.with.failures, ]
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
index.columns <- c(2, 3, 4, 7, 8, 9:18) + 3
# log features selected
data.sample[, names(data.sample)[index.columns]] <-
log(data.sample[, names(data.sample)[index.columns]] + 1 )
# standar features
index.columns <- grep('attr', names(data.sample))
summary(data.sample)
for ( i in index.columns ){
temp <- data.sample[, names(data.sample)[i]]
data.sample[, names(data.sample)[i]] <- scale(temp)
}
ggplot(data.sample, aes(attribute1, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() + theme(legend.position="none")
ggplot(data.sample, aes(attribute2, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute3, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal() +theme(legend.position="none")
ggplot(data.sample, aes(attribute4, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute5, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute6, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute7, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute8, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
ggplot(data.sample, aes(attribute9, fill =  as.character(failure), alpha=.01)) +
geom_density()  + theme_minimal()+theme(legend.position="none")
createPartition <- function(data_, p=0.7){
# Inputs: data_ (data.frame) to split
#         p (numeric): dataframe's proportion for train sample
t <- unique(data_$device)
n <- length(t)
n.p <- round(n*p, 0)
t.sample <- sample(t, n.p)
train.index <- which( data_$device %in% t.sample)
return(train.index)
}
f1 <- function (data, lev = NULL, model = NULL) {
# Function requiere to calculate F1 score within caret::train , see doc.
precision <- posPredValue(data$pred, data$obs, positive = "Failure")
recall  <- sensitivity(data$pred, data$obs, positive = "Failure")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
return(f1_val)
}
set.seed(0)
data.sample$failure <- factor(data.sample$failure)
levels(data.sample$failure) <- c('NoFailure', 'Failure')
train.index <- createPartition(data.sample)
data.sample$date <- data.sample$device <- NULL
train <- data.sample[train.index, ]
test <- data.sample[-train.index, ]
fit.control <- trainControl(  method = 'repeatedcv', number = 10, repeats = 3,
allowParallel = TRUE, classProbs = TRUE,
summaryFunction = f1,  sampling =  "up")
set.seed(0)
gbmFit1 <- train(failure ~ ., data = train, method = "gbm", trControl = fit.control,
verbose = FALSE)
xgb.Fit1 <- train(failure ~ ., data = train, method = "xgbTree", #tuneLength = 5, search= 'random',
trControl = fit.control,
verbose = FALSE)
rf.Fit1 <- train(failure ~ ., data = train, method = "rf", trControl = fit.control,
verbose = FALSE)
rlg.Fit1 <- train(failure ~ ., data = train, method = "regLogistic",
trControl = fit.control, verbose = FALSE)
resamps <- resamples(list(GBM = gbmFit1, XGB = xgb.Fit1,
RF = rf.Fit1, RLG=rlg.Fit1  ))
summary(resamps)
#summary(diff(resamps))
t2 <- Sys.time()
t2 - t1
confusionMatrix(predict(rf.Fit1$finalModel,test), test$failure)
confusionMatrix(predict(xgb.Fit1,test), test$failure)
t3 <- Sys.time()
set.seed(0)
tune_grid <- expand.grid(nrounds=c(100,300), max_depth = c(4:7), eta = c(0.05, 1),   gamma = c(0.01),
colsample_bytree = c(0.75), subsample = c(0.50),  min_child_weight = c(0))
xgb_fit <- train(failure ~., data = train, method = "xgbTree",
trControl= fit.control,
tuneGrid = tune_grid,
tuneLength = 10)
tune_grid <- expand.grid(.mtry = (1:16))
rf_fit <- train(failure ~., data = train, method = "rf",
trControl= fit.control,
tuneGrid = tune_grid,
tuneLength = 10)
###############################
path <- "C:/Users/usuario/Desktop/GitHub/RMF2Coppel/neo4j/Foo/"
setwd(path)
dir()
?M.td
###############################
path <- "C:/Users/usuario/Desktop/GitHub/RMF2Coppel/neo4j/Foo/"
##################
# Ejercicio 1
###################
# Obtencion de las frecuencias de las palabras en los dorpus positivo,negativo y general
# del train
Train.neg <- M.td(direccion ="pord_prod.csv" )
direccion ="pord_prod.csv"
#Obtencion de los conteos de palabras
# direccion (string): con la ruta donde se encuentran los archivos
# la forma facil es con esta implementacion 1
# la otra es hacerlo a mano como lo hice en la tarea2
corpus <- Corpus(DirSource(direccion, recursive=TRUE,
encoding = "UTF-8"),
readerControl=list(language="es"))
#SELECT  distinct *  from
#(SELECT  1000000*(CASE des_Area WHEN 'Muebles' THEN 2  WHEN 'Ropa' THEN 1 ELSE 3 END) + 100000 * #idu_DepartamentoCodigo+1000 *idu_ClaseCodigo + idu_FamiliaCodigo as id_prodclase,
# --des_Departamento as Departamento , des_Clase as Clase, des_Familia as Familia, des_Categoria as Categoria, des_Subcategoria as Subcategoria,
# idu_ArticuloCodigo, des_Articulo
#  FROM `rmf2gcp.Desarrollo.productos_descripcion_cruda`) as a
#order by id_prodclase
##################################
##librerias
library(tm)
library(xtable)
library(caret)
library(e1071)
#Obtencion de los conteos de palabras
# direccion (string): con la ruta donde se encuentran los archivos
# la forma facil es con esta implementacion 1
# la otra es hacerlo a mano como lo hice en la tarea2
corpus <- Corpus(DirSource(direccion, recursive=TRUE,
encoding = "UTF-8"),
readerControl=list(language="es"))
#Obtencion de los conteos de palabras
# direccion (string): con la ruta donde se encuentran los archivos
# la forma facil es con esta implementacion 1
# la otra es hacerlo a mano como lo hice en la tarea2
corpus <- Corpus(DirSource(direccion, recursive=FALSE,
encoding = "UTF-8"),
readerControl=list(language="es"))
DirSource(direccion, recursive=FALSE,
encoding = "UTF-8")
direccion
?Corous
?Corpus
data <- read.csv(file='pord_prod.csv')
View(data)
